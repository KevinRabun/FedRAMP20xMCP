# ADS PATTERNS V2 - Complete Implementation
# Authorization Data Sharing Family
# FedRAMP 20x Requirements: FRR-ADS-01 through FRR-ADS-10
#
# This file contains comprehensive patterns for detecting compliance with
# FedRAMP authorization data sharing requirements, including machine-readable
# formats, API access, and data consistency automation.

---
pattern_id: ads.machine_readable.json_export
name: JSON Export for Audit Data
description: Detects JSON serialization of audit data for machine-readable format compliance per FRR-ADS-01
family: ADS
severity: INFO
pattern_type: function_call

languages:
  python:
    ast_queries:
      - query_type: function_call
        target: json.dumps
      - query_type: function_call
        target: json.dump
    regex_fallback: '(json\.dumps\(|json\.dump\()'
    positive_indicators:
      - json.dumps
      - json.dump
      - JSONEncoder
      
  csharp:
    ast_queries:
      - query_type: function_call
        target: JsonSerializer.Serialize
      - query_type: function_call
        target: JsonConvert.SerializeObject
    regex_fallback: '(JsonSerializer\.Serialize|JsonConvert\.SerializeObject)'
    positive_indicators:
      - JsonSerializer.Serialize
      - JsonConvert.SerializeObject
      
  java:
    ast_queries:
      - query_type: function_call
        target: ObjectMapper
      - query_type: function_call
        target: Gson
    regex_fallback: '(ObjectMapper|Gson.*toJson)'
    positive_indicators:
      - ObjectMapper
      - Gson
      
  typescript:
    ast_queries:
      - query_type: function_call
        target: JSON.stringify
    regex_fallback: 'JSON\.stringify'
    positive_indicators:
      - JSON.stringify

finding:
  title_template: JSON export detected for audit data
  description_template: 'Code exports data in JSON format, supporting machine-readable compliance per FRR-ADS-01. This is a positive indicator of compliance with FedRAMP requirements for authorization data sharing.'
  remediation_template: 'Ensure JSON export includes all required audit fields: timestamp, userId, action, resourceId, outcome, sourceIp. Validate JSON structure matches documented schema.'
  evidence_collection:
    - JSON schema documentation
    - Sample exported JSON files
    - Code implementing JSON export logic
  azure_services:
    - Azure Blob Storage (for JSON file storage)
    - Azure Data Lake (for large-scale JSON exports)
    - Azure API Management (for JSON API endpoints)

tags:
  - machine-readable
  - json
  - positive
  - audit-data

nist_controls:
  - au-2
  - au-3
  - au-12
  - pm-9
  
related_ksis:
  - KSI-AFR-01
  
related_frrs:
  - FRR-ADS-01
  - FRR-ADS-02

evidence_artifacts:
  - artifact_type: configuration
    name: JSON export schema definition
    source: Code repository - schema files
    frequency: on_change
    retention_months: 36
    format: JSON Schema
    
  - artifact_type: logs
    name: JSON export operation logs
    source: Azure Monitor - Application Logs
    frequency: continuous
    retention_months: 36
    format: JSON
    
  - artifact_type: report
    name: JSON format validation report
    source: Automated testing pipeline
    frequency: weekly
    retention_months: 12
    format: HTML/PDF

evidence_collection:
  azure_monitor_kql:
    - query: |
        AppTraces
        | where TimeGenerated > ago(30d)
        | where Message contains "json" and Message contains "export"
        | summarize count() by bin(TimeGenerated, 1h), SeverityLevel
        | order by TimeGenerated desc
      description: Track JSON export operations over last 30 days
      retention_days: 730
      
  azure_cli:
    - command: |
        az monitor log-analytics query \
          --workspace $WORKSPACE_ID \
          --analytics-query "AppTraces | where Message contains 'json.dumps' | take 100" \
          --output json
      description: Query recent JSON serialization events
      output_format: json
      
  powershell:
    - script: |
        # Check for JSON export files in Azure Blob Storage
        $context = New-AzStorageContext -StorageAccountName $storageAccount
        Get-AzStorageBlob -Container "audit-exports" -Context $context `
          | Where-Object { $_.Name -like "*.json" } `
          | Select-Object Name, LastModified, Length
      description: Verify JSON export files exist in storage
      
  rest_api:
    - endpoint: /subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.Storage/storageAccounts/{account}/blobServices/default/containers/audit-exports/blobs
      method: GET
      description: List JSON export files via Azure Storage REST API

automation:
  json_schema_validation:
    description: Automated JSON schema validation in CI/CD pipeline
    implementation: |
      # GitHub Actions example
      - name: Validate JSON Schema
        run: |
          pip install jsonschema
          python -m jsonschema -i export-sample.json audit-schema.json
          
      # Azure Pipeline example
      - task: PowerShell@2
        displayName: 'Validate JSON Export Schema'
        inputs:
          script: |
            $schema = Get-Content ./schemas/audit-export.schema.json | ConvertFrom-Json
            $sample = Get-Content ./samples/export.json | ConvertFrom-Json
            Test-Json -Json ($sample | ConvertTo-Json) -Schema ($schema | ConvertTo-Json)
    azure_services:
      - Azure Pipelines
      - GitHub Advanced Security
    effort_hours: 2
    
  continuous_monitoring:
    description: Azure Monitor alerts for JSON export failures
    implementation: |
      # Bicep template for alert rule
      resource jsonExportAlert 'Microsoft.Insights/metricAlerts@2018-03-01' = {
        name: 'json-export-failure-alert'
        location: 'global'
        properties: {
          description: 'Alert when JSON export operations fail'
          severity: 2
          enabled: true
          scopes: [
            applicationInsights.id
          ]
          evaluationFrequency: 'PT5M'
          windowSize: 'PT15M'
          criteria: {
            'odata.type': 'Microsoft.Azure.Monitor.SingleResourceMultipleMetricCriteria'
            allOf: [
              {
                name: 'ExportFailures'
                metricName: 'exceptions/count'
                operator: 'GreaterThan'
                threshold: 5
                timeAggregation: 'Count'
              }
            ]
          }
        }
      }
    azure_services:
      - Azure Monitor
      - Application Insights
    effort_hours: 3

implementation:
  prerequisites:
    - Azure subscription with Contributor access
    - Application Insights instance configured
    - Azure Blob Storage account for exports
    - JSON schema defined and documented
    
  steps:
    - step: 1
      action: Define JSON schema for audit data exports
      azure_service: None (local development)
      estimated_hours: 4
      validation: Schema validates against JSON Schema Draft 7 specification
      
    - step: 2
      action: Implement JSON serialization in application code
      azure_service: Application code
      estimated_hours: 8
      validation: Unit tests pass for JSON export functions
      bicep_template: N/A
      
    - step: 3
      action: Configure Azure Blob Storage for JSON exports
      azure_service: Azure Blob Storage
      estimated_hours: 2
      validation: Storage container created with appropriate access controls
      bicep_template: templates/bicep/storage/blob-storage-audit.bicep
      
    - step: 4
      action: Set up Application Insights tracking for exports
      azure_service: Application Insights
      estimated_hours: 2
      validation: Export operations logged to Application Insights
      
    - step: 5
      action: Create automated schema validation in CI/CD
      azure_service: Azure Pipelines
      estimated_hours: 3
      validation: Pipeline validates JSON output against schema
      
  validation_queries:
    - az storage blob list --account-name <account> --container-name audit-exports --query "[?contains(name, '.json')]"
    - az monitor app-insights query --app <app-id> --analytics-query "traces | where message contains 'json.dumps'"
    
  total_effort_hours: 19

ssp_mapping:
  control_family: AU - Audit and Accountability
  control_numbers:
    - AU-2
    - AU-3
    - AU-12
    - PM-9
    
  ssp_sections:
    - section: "AU-2: Audit Events"
      description_template: |
        The system generates audit records in machine-readable JSON format for all
        security-relevant events. JSON exports include standardized fields (timestamp,
        userId, action, resourceId, outcome, sourceIp) enabling automated processing
        and analysis. This supports FedRAMP authorization data sharing requirements
        per FRR-ADS-01.
      
      implementation_details: |
        Application code uses Python's json.dumps() (or language-equivalent) to
        serialize audit events to JSON format. JSON schema is defined and validated
        in CI/CD pipeline. Exports are stored in Azure Blob Storage with 36-month
        retention for FedRAMP compliance.
      
      evidence_references:
        - JSON schema definition file (audit-export.schema.json)
        - Sample JSON export files from production
        - Application Insights logs showing export operations
        - CI/CD pipeline validation results
    
    - section: "PM-9: Risk Management Strategy"
      description_template: |
        Machine-readable JSON exports enable automated risk assessment and continuous
        monitoring. External parties can programmatically access authorization data
        to assess system risk posture, supporting FedRAMP authorization decisions.
      
      implementation_details: |
        JSON exports are available via Azure Blob Storage with SAS token access for
        authorized external reviewers. REST API endpoints provide programmatic access
        to current authorization data, supporting automated risk assessment tools.
      
      evidence_references:
        - Azure Blob Storage access logs
        - API usage metrics from Azure API Management
        - JSON export schema and samples

azure_guidance:
  recommended_services:
    - service: Azure Blob Storage
      tier: Standard (Hot tier for frequent access)
      purpose: Store exported JSON audit files with long-term retention
      monthly_cost_estimate: "$20-50 for typical audit data volumes (1-10GB)"
      alternatives:
        - Azure Data Lake Storage Gen2 (for very large volumes)
        
    - service: Application Insights
      tier: Standard
      purpose: Track JSON export operations and errors
      monthly_cost_estimate: "$10-30 based on ingestion volume"
      alternatives:
        - Azure Monitor Logs directly (lower cost, less features)
  
  well_architected_framework:
    pillar: Operational Excellence
    design_area: Monitoring and diagnostics
    recommendation_id: OE-07
    reference_url: https://learn.microsoft.com/azure/well-architected/operational-excellence/observability
  
  cloud_adoption_framework:
    stage: Manage
    guidance: Implement structured logging and export for compliance requirements
    reference_url: https://learn.microsoft.com/azure/cloud-adoption-framework/manage/monitor/

compliance_frameworks:
  fedramp_20x:
    requirement_id: FRR-ADS-01
    requirement_name: Public Information (Machine-Readable)
    impact_levels:
      - Low
      - Moderate
      - High
    
  nist_800_53_rev5:
    controls:
      - AU-2
      - AU-3
      - AU-12
      - PM-9
    
  pci_dss_4:
    requirements:
      - "10.2.1"
      - "10.2.2"
    
  hipaa:
    standards:
      - "164.312(b) - Audit controls"

testing:
  positive_test_cases:
    - description: Python json.dumps detected
      code_sample: |
        import json
        audit_data = {"timestamp": "2025-12-13T10:00:00Z", "userId": "user123"}
        json_output = json.dumps(audit_data)
      expected_severity: INFO
      expected_finding: true
      
    - description: C# JsonSerializer.Serialize detected
      code_sample: |
        using System.Text.Json;
        var auditData = new { Timestamp = DateTime.UtcNow, UserId = "user123" };
        string jsonOutput = JsonSerializer.Serialize(auditData);
      expected_severity: INFO
      expected_finding: true
      
  negative_test_cases:
    - description: No JSON export present
      code_sample: |
        audit_data = {"timestamp": "2025-12-13", "userId": "user123"}
        print(audit_data)  # Not exported to JSON
      expected_severity: NONE
      expected_finding: false
      
  validation_scripts:
    - tests/test_ads_patterns.py::test_json_export_detection
    - tests/test_ads_patterns.py::test_json_export_no_false_positives

---
pattern_id: ads.machine_readable.xml_export
name: XML Export for Audit Data  
description: Detects XML serialization for machine-readable audit data per FRR-ADS-01
family: ADS
severity: INFO
pattern_type: function_call

languages:
  python:
    ast_queries:
      - query_type: import_statement
        target: xml.etree.ElementTree
      - query_type: import_statement
        target: lxml
    regex_fallback: '(xml\.etree\.ElementTree|import lxml|from lxml)'
    positive_indicators:
      - xml.etree.ElementTree
      - lxml
      
  csharp:
    ast_queries:
      - query_type: using_directive
        target: System.Xml.Serialization
    regex_fallback: 'using System\.Xml'
    positive_indicators:
      - XmlSerializer
      - XmlWriter
      
  java:
    ast_queries:
      - query_type: import_declaration
        target: javax.xml
    regex_fallback: 'import javax\.xml'
    positive_indicators:
      - DocumentBuilder
      - JAXBContext
      
  typescript:
    ast_queries:
      - query_type: import_statement
        target: xml2js
    regex_fallback: "(import.*xml2js|require.*xml2js)"
    positive_indicators:
      - xml2js
      - fast-xml-parser

finding:
  title_template: XML export detected for audit data
  description_template: 'Code exports data in XML format, supporting machine-readable compliance. For FedRAMP, prefer OSCAL-formatted XML when applicable.'
  remediation_template: 'Validate XML output conforms to required schema (OSCAL schema for FedRAMP authorization data). Ensure XML includes all required audit fields.'
  evidence_collection:
    - XML schema/DTD documentation
    - Sample XML export files
    - OSCAL validation results (if applicable)
  azure_services:
    - Azure Blob Storage
    - Azure API Management

tags:
  - machine-readable
  - xml
  - oscal
  - positive

nist_controls:
  - au-2
  - pm-9
  
related_ksis:
  - KSI-AFR-01
  
related_frrs:
  - FRR-ADS-01

evidence_artifacts:
  - artifact_type: configuration
    name: XML/OSCAL schema files
    source: Code repository
    frequency: on_change
    retention_months: 36
    format: XSD
    
  - artifact_type: report
    name: OSCAL validation report
    source: Automated validation pipeline
    frequency: weekly
    retention_months: 12
    format: PDF

evidence_collection:
  azure_cli:
    - command: |
        az storage blob list --account-name $STORAGE_ACCOUNT \
          --container-name audit-exports \
          --query "[?contains(name, '.xml') || contains(name, '.oscal')]" \
          --output table
      description: List XML/OSCAL export files in storage
      output_format: table

automation:
  oscal_validation:
    description: Automated OSCAL/XML schema validation
    implementation: |
      # GitHub Actions using oscal-cli
      - name: Validate OSCAL Files
        run: |
          # Install OSCAL CLI
          wget https://repo1.maven.org/maven2/gov/nist/secauto/oscal/tools/oscal-cli/cli-core/1.0.2/cli-core-1.0.2-oscal-cli.zip
          unzip cli-core-1.0.2-oscal-cli.zip
          
          # Validate OSCAL file
          ./oscal-cli/bin/oscal-cli ssp validate ssp.oscal.xml
    azure_services:
      - Azure Pipelines
      - GitHub Actions
    effort_hours: 4

implementation:
  prerequisites:
    - Understanding of XML/OSCAL formats
    - OSCAL schema files (if using OSCAL)
    - XML validation tools installed
    
  steps:
    - step: 1
      action: Review OSCAL specifications for FedRAMP
      azure_service: None
      estimated_hours: 4
      validation: Team understands OSCAL SSP format requirements
      
    - step: 2
      action: Implement XML/OSCAL export in code
      azure_service: Application code
      estimated_hours: 12
      validation: XML output validates against schema
      
    - step: 3
      action: Set up CI/CD validation for XML exports
      azure_service: Azure Pipelines
      estimated_hours: 3
      validation: Pipeline validates all XML exports automatically
      
  total_effort_hours: 19

ssp_mapping:
  control_family: AU - Audit and Accountability
  control_numbers:
    - AU-2
    - PM-9
    
  ssp_sections:
    - section: "AU-2: Audit Events"
      description_template: |
        The system can export audit and authorization data in XML format, including
        OSCAL-formatted exports when applicable. XML exports support FedRAMP
        authorization data sharing requirements (FRR-ADS-01).
      implementation_details: |
        Application uses standard XML serialization libraries to generate well-formed
        XML documents. For FedRAMP authorization data (SSP, SAP, SAR), the system
        supports OSCAL format exports validated against NIST OSCAL schemas.
      evidence_references:
        - OSCAL SSP XML samples
        - XML schema validation results
        - OSCAL validation pipeline logs

azure_guidance:
  recommended_services:
    - service: Azure Blob Storage
      tier: Standard
      purpose: Store XML/OSCAL files
      monthly_cost_estimate: "$20-40"
      alternatives: []
  
  well_architected_framework:
    pillar: Operational Excellence
    design_area: Standards compliance
    recommendation_id: OE-08
    reference_url: https://learn.microsoft.com/azure/well-architected/operational-excellence/

compliance_frameworks:
  fedramp_20x:
    requirement_id: FRR-ADS-01
    requirement_name: Public Information (Machine-Readable - OSCAL)
    impact_levels:
      - Low
      - Moderate
      - High
    
  nist_800_53_rev5:
    controls:
      - AU-2
      - PM-9

testing:
  positive_test_cases:
    - description: Python ElementTree XML export
      code_sample: |
        import xml.etree.ElementTree as ET
        root = ET.Element("AuditRecord")
        ET.SubElement(root, "Timestamp").text = "2025-12-13T10:00:00Z"
        tree = ET.ElementTree(root)
      expected_severity: INFO
      expected_finding: true
      
  negative_test_cases:
    - description: No XML export
      code_sample: |
        data = {"timestamp": "2025-12-13"}
        print(data)
      expected_severity: NONE
      expected_finding: false
      
  validation_scripts:
    - tests/test_ads_patterns.py::test_xml_export_detection

